As a Data Engineer at a software company, you are tasked with optimizing the performance of your Apache Kafka cluster. Kafka topics are used to manage data streams, and each topic is divided into partitions. Efficient partitioning of these topics can significantly reduce latency and improve throughput. Your goal is to determine the optimal number of partitions for each topic and assign these partitions to brokers in a way that balances the load and minimizes data transfer between brokers.

Given the following data about your Kafka cluster and topics, use integer linear programming to find the optimal solution.

Objective:
Maximize throughput by minimizing data transfer between brokers.
You calculate this by for every topic, calculating the average of transfer between all brokers based on the number of partitions they have assigned for that topic.

Constraints:
- Partition Capacity Constraint: The number of partitions assigned to each broker must not exceed the broker's maximum capacity.
- Topic Partition Constraint: The number of partitions assigned to each topic must lie within the specified range.
- Broker Load Balance Constraint: The total number of partitions assigned to each broker should be as balanced as possible, with no broker having more than 20% of the broker average.
- Partition Distribution Constraint: For each topic, no broker can hold more than 40% of the partitions.

Data:
The Brokers can be found in kafka_brokers.csv and has the following columns: Broker_ID,Max_Partitions
The Topics can be found in kafka_topics.csv and has the following columns: Topic_ID,Min_Partitions,Max_Partitions
The Data Transfer rates can be found in kafka_rates.csv and has the following columns: From_Broker,To_Broker,Transfer_Rate
